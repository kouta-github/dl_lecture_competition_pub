{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 必要なモジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # 正規表現操作を行うためのモジュール\n",
    "import random  # 乱数生成のためのモジュール\n",
    "import time  # 時間の計測や操作を行うためのモジュール\n",
    "from statistics import mode  # 最頻値（モード）を計算するためのモジュール\n",
    "\n",
    "from PIL import Image  # Python Imaging Library（PIL）を使って画像を処理するためのモジュール\n",
    "import numpy as np  # 数値計算を効率的に行うためのライブラリ\n",
    "import pandas as pd  # データ操作や解析を行うためのライブラリ\n",
    "import torch  # PyTorch: ディープラーニングのためのフレームワーク\n",
    "import torch.nn as nn  # ニューラルネットワークモジュール\n",
    "import torchvision  # 画像処理用のPyTorchモジュール\n",
    "from torchvision import transforms  # 画像変換用のモジュール\n",
    "\n",
    "# Jupyter Notebook用にインラインで画像を表示するためのモジュール\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. シード値の設定関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)  # randomモジュールのシードを設定して、乱数生成の再現性を確保します。\n",
    "    np.random.seed(seed)  # NumPyモジュールのシードを設定して、乱数生成の再現性を確保します。\n",
    "    torch.manual_seed(seed)  # PyTorchのCPU上での乱数生成のシードを設定して、再現性を確保します。\n",
    "    torch.cuda.manual_seed(seed)  # PyTorchのGPU上での乱数生成のシードを設定して、再現性を確保します。\n",
    "    torch.cuda.manual_seed_all(seed)  # 複数のGPUを使用する場合に、全てのGPUでの乱数生成のシードを設定します。\n",
    "    torch.backends.cudnn.deterministic = True  # CuDNNを使用する場合の再現性を確保するために、決定論的な挙動を有効にします。\n",
    "    torch.backends.cudnn.benchmark = False  # 再現性を確保するために、CuDNNのベンチマークモードを無効にします。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. テキスト処理関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = text.lower()  # テキストを小文字に変換\n",
    "\n",
    "    num_word_to_digit = {  # 数詞を数字に変換する辞書\n",
    "        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n",
    "        'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',\n",
    "        'ten': '10'\n",
    "    }\n",
    "    for word, digit in num_word_to_digit.items():  # 数詞を数字に置き換える\n",
    "        text = text.replace(word, digit)\n",
    "\n",
    "    text = re.sub(r'(?<!\\d)\\.(?!\\d)', '', text)  # 小数点のピリオドを削除\n",
    "\n",
    "    text = re.sub(r'\\b(a|an|the)\\b', '', text)  # 冠詞を削除\n",
    "\n",
    "    contractions = {  # 短縮形を正規の形に戻す辞書\n",
    "        \"dont\": \"don't\", \"isnt\": \"isn't\", \"arent\": \"aren't\", \"wont\": \"won't\",\n",
    "        \"cant\": \"can't\", \"wouldnt\": \"wouldn't\", \"couldnt\": \"couldn't\"\n",
    "    }\n",
    "    for contraction, correct in contractions.items():  # 短縮形を変換\n",
    "        text = text.replace(contraction, correct)\n",
    "\n",
    "    text = re.sub(r\"[^\\w\\s':]\", ' ', text)  # 句読点をスペースに変換\n",
    "\n",
    "    text = re.sub(r'\\s+,', ',', text)  # 不要なスペースを削除\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # 連続するスペースを1つに変換\n",
    "\n",
    "    return text  # 処理したテキストを返す\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. データセットクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df_path, image_dir, transform=None, answer=True):\n",
    "        self.transform = transform  # 画像の前処理を設定\n",
    "        self.image_dir = image_dir  # 画像ファイルのディレクトリを設定\n",
    "        self.df = pd.read_json(df_path)  # JSONファイルを読み込みDataFrameに変換\n",
    "        self.answer = answer  # 回答が含まれるかどうかのフラグを設定\n",
    "\n",
    "        self.question2idx = {}  # 質問文の単語をインデックスに変換する辞書\n",
    "        self.answer2idx = {}  # 回答をインデックスに変換する辞書\n",
    "        self.idx2question = {}  # インデックスを質問文の単語に変換する辞書\n",
    "        self.idx2answer = {}  # インデックスを回答に変換する辞書\n",
    "\n",
    "        for question in self.df[\"question\"]:  # 質問文に含まれる単語を辞書に追加\n",
    "            question = process_text(question)  # テキストを処理\n",
    "            words = question.split(\" \")  # 単語に分割\n",
    "            for word in words:  # 単語を辞書に追加\n",
    "                if word not in self.question2idx:\n",
    "                    self.question2idx[word] = len(self.question2idx)\n",
    "        self.idx2question = {v: k for k, v in self.question2idx.items()}  # インデックスを質問文に変換する辞書を作成\n",
    "\n",
    "        if self.answer:  # 回答がある場合\n",
    "            for answers in self.df[\"answers\"]:  # 回答に含まれる単語を辞書に追加\n",
    "                for answer in answers:\n",
    "                    word = answer[\"answer\"]\n",
    "                    word = process_text(word)\n",
    "                    if word not in self.answer2idx:\n",
    "                        self.answer2idx[word] = len(self.answer2idx)\n",
    "            self.idx2answer = {v: k for k, v in self.answer2idx.items()}  # インデックスを回答に変換する辞書を作成\n",
    "\n",
    "    def update_dict(self, dataset):\n",
    "        self.question2idx = dataset.question2idx  # 訓練データセットの質問文の辞書を更新\n",
    "        self.answer2idx = dataset.answer2idx  # 訓練データセットの回答の辞書を更新\n",
    "        self.idx2question = dataset.idx2question  # 訓練データセットの質問文の逆引き辞書を更新\n",
    "        self.idx2answer = dataset.idx2answer  # 訓練データセットの回答の逆引き辞書を更新\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(f\"{self.image_dir}/{self.df['image'][idx]}\")  # 画像を読み込む\n",
    "        image = self.transform(image)  # 画像を前処理する\n",
    "        question = np.zeros(len(self.idx2question) + 1)  # 質問文のone-hotベクトルを初期化\n",
    "        question_words = self.df[\"question\"][idx].split(\" \")  # 質問文を単語に分割\n",
    "        for word in question_words:  # 質問文の単語をone-hotベクトルに変換\n",
    "            try:\n",
    "                question[self.question2idx[word]] = 1\n",
    "            except KeyError:\n",
    "                question[-1] = 1  # 未知語の場合\n",
    "\n",
    "        if self.answer:  # 回答がある場合\n",
    "            answers = [self.answer2idx[process_text(answer[\"answer\"])] for answer in self.df[\"answers\"][idx]]\n",
    "            mode_answer_idx = mode(answers)  # 最頻値を取得\n",
    "            return image, torch.Tensor(question), torch.Tensor(answers), int(mode_answer_idx)  # 画像、質問、回答、最頻値の回答を返す\n",
    "        else:\n",
    "            return image, torch.Tensor(question)  # 画像と質問を返す\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)  # データセットのサイズを返す\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 評価指標関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VQA_criterion(batch_pred, batch_answers):\n",
    "    total_acc = 0.  # 総合正解率を初期化\n",
    "    for pred, answers in zip(batch_pred, batch_answers):  # バッチ内の各予測と対応する回答をループ\n",
    "        acc = 0.  # 個々の正解率を初期化\n",
    "        for i in range(len(answers)):  # 各回答についてループ\n",
    "            num_match = 0  # 一致した回答の数を初期化\n",
    "            for j in range(len(answers)):  # 他の回答についてループ\n",
    "                if i == j:  # 自分自身との比較をスキップ\n",
    "                    continue\n",
    "                if pred == answers[j]:  # 予測と回答が一致した場合\n",
    "                    num_match += 1  # 一致数をカウント\n",
    "            acc += min(num_match / 3, 1)  # 正解率を計算し、最大値を1とする\n",
    "        total_acc += acc / 10  # 正解率の平均を計算し、総合正解率に加算\n",
    "    return total_acc / len(batch_pred)  # バッチ内の平均正解率を返す\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1  # 拡張係数を設定（BasicBlockの場合は1）\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)  # 最初の畳み込み層\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)  # バッチ正規化層\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)  # 2番目の畳み込み層\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)  # バッチ正規化層\n",
    "        self.relu = nn.ReLU(inplace=True)  # 活性化関数\n",
    "\n",
    "        self.shortcut = nn.Sequential()  # ショートカット（恒等写像）\n",
    "        if stride != 1 or in_channels != out_channels:  # チャネル数が一致しない場合やストライドが1でない場合\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),  # 1x1の畳み込み層\n",
    "                nn.BatchNorm2d(out_channels)  # バッチ正規化層\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # 入力を保持\n",
    "        out = self.relu(self.bn1(self.conv1(x)))  # 畳み込み->バッチ正規化->ReLU\n",
    "        out = self.bn2(self.conv2(out))  # 畳み込み->バッチ正規化\n",
    "        out += self.shortcut(residual)  # ショートカットを加算\n",
    "        out = self.relu(out)  # ReLUを適用\n",
    "        return out\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    expansion = 4  # 拡張係数を設定（BottleneckBlockの場合は4）\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)  # 1x1の畳み込み層\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)  # バッチ正規化層\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)  # 3x3の畳み込み層\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)  # バッチ正規化層\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1)  # 1x1の畳み込み層\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)  # バッチ正規化層\n",
    "        self.relu = nn.ReLU(inplace=True)  # 活性化関数\n",
    "\n",
    "        self.shortcut = nn.Sequential()  # ショートカット（恒等写像）\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:  # チャネル数が一致しない場合やストライドが1でない場合\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride),  # 1x1の畳み込み層\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)  # バッチ正規化層\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # 入力を保持\n",
    "        out = self.relu(self.bn1(self.conv1(x)))  # 1x1の畳み込み->バッチ正規化->ReLU\n",
    "        out = self.relu(self.bn2(self.conv2(out)))  # 3x3の畳み込み->バッチ正規化->ReLU\n",
    "        out = self.bn3(self.conv3(out))  # 1x1の畳み込み->バッチ正規化\n",
    "        out += self.shortcut(residual)  # ショートカットを加算\n",
    "        out = self.relu(out)  # ReLUを適用\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64  # 初期の入力チャネル数を設定\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)  # 初めの畳み込み層\n",
    "        self.bn1 = nn.BatchNorm2d(64)  # バッチ正規化層\n",
    "        self.relu = nn.ReLU(inplace=True)  # 活性化関数\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # プーリング層\n",
    "\n",
    "        self.layer1 = self._make_layer(block, layers[0], 64)  # 最初のレイヤー\n",
    "        self.layer2 = self._make_layer(block, layers[1], 128, stride=2)  # 2番目のレイヤー\n",
    "        self.layer3 = self._make_layer(block, layers[2], 256, stride=2)  # 3番目のレイヤー\n",
    "        self.layer4 = self._make_layer(block, layers[3], 512, stride=2)  # 4番目のレイヤー\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # 平均プーリング層\n",
    "        self.fc = nn.Linear(512 * block.expansion, 512)  # 全結合層\n",
    "\n",
    "    def _make_layer(self, block, blocks, out_channels, stride=1):\n",
    "        layers = [block(self.in_channels, out_channels, stride)]  # 最初のブロックを追加\n",
    "        self.in_channels = out_channels * block.expansion  # チャネル数を更新\n",
    "        for _ in range(1, blocks):  # 残りのブロックを追加\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)  # ブロックを順次結合してシーケンスを作成\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))  # 畳み込み->バッチ正規化->ReLU\n",
    "        x = self.maxpool(x)  # プーリング\n",
    "        x = self.layer1(x)  # 最初のレイヤー\n",
    "        x = self.layer2(x)  # 2番目のレイヤー\n",
    "        x = self.layer3(x)  # 3番目のレイヤー\n",
    "        x = self.layer4(x)  # 4番目のレイヤー\n",
    "        x = self.avgpool(x)  # 平均プーリング\n",
    "        x = x.view(x.size(0), -1)  # 平坦化\n",
    "        x = self.fc(x)  # 全結合層\n",
    "        return x\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])  # ResNet18モデルを作成\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(BottleneckBlock, [3, 4, 6, 3])  # ResNet50モデルを作成\n",
    "\n",
    "\n",
    "class VQAModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_answer):\n",
    "        super().__init__()\n",
    "        self.resnet = ResNet18()  # ResNet18モデルを初期化\n",
    "        self.text_encoder = nn.Linear(vocab_size, 512)  # 質問文をエンコードする全結合層\n",
    "\n",
    "        self.fc = nn.Sequential(  # 最後の全結合層\n",
    "            nn.Linear(1024, 512),  # 画像特徴量(512)と質問文特徴量(512)を結合したものを入力\n",
    "            nn.BatchNorm1d(512),  # Batch Normalization\n",
    "            nn.ReLU(inplace=True),  # 活性化関数ReLU\n",
    "            nn.Dropout(0.4),  # Dropout\n",
    "            nn.Linear(512, 256),  # 次の全結合層への変換\n",
    "            nn.BatchNorm1d(256),  # Batch Normalization\n",
    "            nn.ReLU(inplace=True),  # 活性化関数ReLU\n",
    "            nn.Dropout(0.4),  # Dropout\n",
    "            nn.Linear(256, n_answer)  # 最終的な出力層\n",
    "        )\n",
    "\n",
    "    def forward(self, image, question):\n",
    "        image_feature = self.resnet(image)  # 画像特徴量を抽出（N, 512）\n",
    "        question_feature = self.text_encoder(question)  # 質問文の特徴量を抽出（N, 512）\n",
    "        x = torch.cat([image_feature, question_feature], dim=1)  # 画像特徴量と質問文特徴量を結合（N, 1024）\n",
    "        x = self.fc(x)  # 全結合層を通す（N, n_answer）\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 学習と評価の関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()  # モデルを訓練モードに設定\n",
    "    total_loss = 0  # 総損失を初期化\n",
    "    total_acc = 0  # 総正解率を初期化\n",
    "    simple_acc = 0  # シンプル正解率を初期化\n",
    "    start = time.time()  # 訓練の開始時間を記録\n",
    "\n",
    "    for image, question, answers, mode_answer in dataloader:  # データローダーからバッチを取得\n",
    "        image, question, answers, mode_answer = image.to(device), question.to(device), answers.to(device), mode_answer.to(device)  # デバイスにデータを転送\n",
    "        pred = model(image, question)  # モデルにデータを入力して予測を取得\n",
    "        loss = criterion(pred, mode_answer.squeeze())  # 損失を計算\n",
    "\n",
    "        optimizer.zero_grad()  # 勾配をゼロにリセット\n",
    "        loss.backward()  # 誤差逆伝播を実行\n",
    "        optimizer.step()  # パラメータを更新\n",
    "\n",
    "        total_loss += loss.item()  # 総損失を更新\n",
    "        total_acc += VQA_criterion(pred.argmax(1), answers)  # 総正解率を更新\n",
    "        simple_acc += (pred.argmax(1) == mode_answer).float().mean().item()  # シンプル正解率を更新\n",
    "\n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader), simple_acc / len(dataloader), time.time() - start  # 平均損失、正解率、シンプル正解率、訓練時間を返す\n",
    "\n",
    "\n",
    "def eval(model, dataloader, optimizer, criterion, device):\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    total_loss = 0  # 総損失を初期化\n",
    "    total_acc = 0  # 総正解率を初期化\n",
    "    simple_acc = 0  # シンプル正解率を初期化\n",
    "    start = time.time()  # 評価の開始時間を記録\n",
    "\n",
    "    with torch.no_grad():  # 評価中は勾配を計算しない\n",
    "        for image, question, answers, mode_answer in dataloader:  # データローダーからバッチを取得\n",
    "            image, question, answers, mode_answer = image.to(device), question.to(device), answers.to(device), mode_answer.to(device)  # デバイスにデータを転送\n",
    "            pred = model(image, question)  # モデルにデータを入力して予測を取得\n",
    "            loss = criterion(pred, mode_answer.squeeze())  # 損失を計算\n",
    "\n",
    "            total_loss += loss.item()  # 総損失を更新\n",
    "            total_acc += VQA_criterion(pred.argmax(1), answers)  # 総正解率を更新\n",
    "            simple_acc += (pred.argmax(1) == mode_answer).mean().item()  # シンプル正解率を更新\n",
    "\n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader), simple_acc / len(dataloader), time.time() - start  # 平均損失、正解率、シンプル正解率、評価時間を返す\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. メイン関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットのパスやその他の設定\n",
    "train_json_path = \"./data/train.json\"  # 訓練データのJSONファイルのパス\n",
    "valid_json_path = \"./data/valid.json\"  # 検証データのJSONファイルのパス\n",
    "train_image_dir = \"./data/train\"  # 訓練画像のディレクトリパス\n",
    "valid_image_dir = \"./data/valid\"  # 検証画像のディレクトリパス\n",
    "model_path = \"model.pth\"  # モデルパラメータを保存するファイルのパス\n",
    "submission_path = \"submission.npy\"  # 提出用の予測結果を保存するファイルのパス\n",
    "num_epoch = 20 # エポック数\n",
    "batch_size = 128  # バッチサイズ\n",
    "learning_rate = 0.001  # 学習率\n",
    "weight_decay = 1e-5  # 重み減衰（L2正則化）\n",
    "seed = 42  # ランダムシード\n",
    "\n",
    "set_seed(seed)  # ランダムシードを設定\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 使用するデバイスを設定\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 画像を224x224にリサイズ\n",
    "    transforms.RandomHorizontalFlip(),  # 水平方向にランダムに反転\n",
    "    transforms.RandomRotation(10),  # ランダムに回転 (±10度)\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # カラージッター\n",
    "    transforms.ToTensor(),  # 画像をテンソルに変換\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ノーマライゼーション\n",
    "])\n",
    "\n",
    "train_dataset = VQADataset(df_path=train_json_path, image_dir=train_image_dir, transform=transform)  # 訓練データセットを作成\n",
    "test_dataset = VQADataset(df_path=valid_json_path, image_dir=valid_image_dir, transform=transform, answer=False)  # 検証データセットを作成\n",
    "test_dataset.update_dict(train_dataset)  # 検証データセットの辞書を訓練データセットに合わせて更新\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # 訓練データローダーを作成\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)  # 検証データローダーを作成\n",
    "\n",
    "model = VQAModel(vocab_size=len(train_dataset.question2idx)+1, n_answer=len(train_dataset.answer2idx)).to(device)  # モデルを初期化\n",
    "criterion = nn.CrossEntropyLoss()  # 損失関数を設定\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # オプティマイザを設定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練エポック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【1/20】\n",
      "train time: 1770.84 [s]\n",
      "train loss: 6.8321\n",
      "train acc: 0.4261\n",
      "train simple acc: 0.3432\n",
      "【2/20】\n",
      "train time: 1845.76 [s]\n",
      "train loss: 5.6106\n",
      "train acc: 0.4756\n",
      "train simple acc: 0.3846\n",
      "【3/20】\n",
      "train time: 1790.95 [s]\n",
      "train loss: 5.3136\n",
      "train acc: 0.4776\n",
      "train simple acc: 0.3879\n",
      "【4/20】\n",
      "train time: 1133.67 [s]\n",
      "train loss: 5.1251\n",
      "train acc: 0.4833\n",
      "train simple acc: 0.3942\n",
      "【5/20】\n",
      "train time: 469.19 [s]\n",
      "train loss: 4.9703\n",
      "train acc: 0.4858\n",
      "train simple acc: 0.3974\n",
      "【6/20】\n",
      "train time: 448.95 [s]\n",
      "train loss: 4.8493\n",
      "train acc: 0.4865\n",
      "train simple acc: 0.3996\n",
      "【7/20】\n",
      "train time: 434.65 [s]\n",
      "train loss: 4.7123\n",
      "train acc: 0.4913\n",
      "train simple acc: 0.4051\n",
      "【8/20】\n",
      "train time: 423.90 [s]\n",
      "train loss: 4.5807\n",
      "train acc: 0.4928\n",
      "train simple acc: 0.4063\n",
      "【9/20】\n",
      "train time: 424.83 [s]\n",
      "train loss: 4.4637\n",
      "train acc: 0.4948\n",
      "train simple acc: 0.4102\n",
      "【10/20】\n",
      "train time: 425.34 [s]\n",
      "train loss: 4.3477\n",
      "train acc: 0.4971\n",
      "train simple acc: 0.4124\n",
      "【11/20】\n",
      "train time: 423.39 [s]\n",
      "train loss: 4.2426\n",
      "train acc: 0.4981\n",
      "train simple acc: 0.4146\n",
      "【12/20】\n",
      "train time: 423.22 [s]\n",
      "train loss: 4.1526\n",
      "train acc: 0.4990\n",
      "train simple acc: 0.4148\n",
      "【13/20】\n",
      "train time: 423.08 [s]\n",
      "train loss: 4.0360\n",
      "train acc: 0.4998\n",
      "train simple acc: 0.4167\n",
      "【14/20】\n",
      "train time: 422.90 [s]\n",
      "train loss: 3.9435\n",
      "train acc: 0.5007\n",
      "train simple acc: 0.4179\n",
      "【15/20】\n",
      "train time: 423.26 [s]\n",
      "train loss: 3.8533\n",
      "train acc: 0.5033\n",
      "train simple acc: 0.4217\n",
      "【16/20】\n",
      "train time: 423.25 [s]\n",
      "train loss: 3.7531\n",
      "train acc: 0.5025\n",
      "train simple acc: 0.4223\n",
      "【17/20】\n",
      "train time: 424.86 [s]\n",
      "train loss: 3.6626\n",
      "train acc: 0.4997\n",
      "train simple acc: 0.4218\n",
      "【18/20】\n",
      "train time: 423.48 [s]\n",
      "train loss: 3.5856\n",
      "train acc: 0.5025\n",
      "train simple acc: 0.4242\n",
      "【19/20】\n",
      "train time: 424.23 [s]\n",
      "train loss: 3.4777\n",
      "train acc: 0.5019\n",
      "train simple acc: 0.4266\n",
      "【20/20】\n",
      "train time: 421.89 [s]\n",
      "train loss: 3.3942\n",
      "train acc: 0.5032\n",
      "train simple acc: 0.4286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epoch):  # エポック数だけループ\n",
    "    train_loss, train_acc, train_simple_acc, train_time = train(model, train_loader, optimizer, criterion, device)  # 訓練を実行し、損失、正解率、シンプル正解率、訓練時間を取得\n",
    "    print(f\"【{epoch + 1}/{num_epoch}】\\n\"  # 現在のエポック数を表示\n",
    "          f\"train time: {train_time:.2f} [s]\\n\"  # 訓練時間を表示\n",
    "          f\"train loss: {train_loss:.4f}\\n\"  # 訓練損失を表示\n",
    "          f\"train acc: {train_acc:.4f}\\n\"  # 訓練正解率を表示\n",
    "          f\"train simple acc: {train_simple_acc:.4f}\")  # シンプル正解率を表示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # モデルを評価モードに設定\n",
    "submission = []  # 提出用の予測結果を保存するリストを初期化\n",
    "\n",
    "for image, question in test_loader:  # テストデータローダーからバッチを取得してループ\n",
    "    image, question = image.to(device), question.to(device)  # デバイスにデータを転送\n",
    "    pred = model(image, question)  # モデルにデータを入力して予測を取得\n",
    "    pred = pred.argmax(1).cpu().item()  # 予測をクラスラベルに変換し、CPUに転送して数値に変換\n",
    "    submission.append(pred)  # 予測結果をリストに追加\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission.npyの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = [train_dataset.idx2answer[id] for id in submission]  # 予測結果のIDを回答テキストに変換\n",
    "submission = np.array(submission)  # 予測結果をNumPy配列に変換\n",
    "torch.save(model.state_dict(), model_path)  # モデルのパラメータをファイルに保存\n",
    "np.save(submission_path, submission)  # 予測結果をファイルに保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlbasics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
